{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage\n",
    "from datetime import date, datetime\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"output_MR.csv\")\n",
    "icd_type = {}\n",
    "\n",
    "for i in df.index:\n",
    "    icd_type[str(df[\"report_uid\"].loc[i])] = df[\"ICD\"].loc[i]\n",
    "    \n",
    "# for i in icd_type.keys():\n",
    "#     print(i, icd_type[i])\n",
    "    \n",
    "# del icd_type[\"380000002899\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nStroke_data.shape: (129, 256, 256, 136)\n",
      "stroke_data.shape: (70, 256, 256, 136)\n"
     ]
    }
   ],
   "source": [
    "# path = \"BRAIN MRA\"\n",
    "# #error_cases = []\n",
    "# sorttt = []\n",
    "\n",
    "# def create_data(icd1, icd2):\n",
    "    \n",
    "#     data = []\n",
    "#     pbar = tqdm(total=len(os.listdir(path)))\n",
    "    \n",
    "#     for folder in sorted(os.listdir(path)):\n",
    "        \n",
    "#         if folder not in icd_type.keys():  \n",
    "#             pbar.update(1)\n",
    "#             continue\n",
    "#         if icd_type[folder] != icd1 and icd_type[folder] != icd2:\n",
    "#             pbar.update(1)\n",
    "#             continue\n",
    "#         if len(os.listdir(os.path.join(os.getcwd(), path, folder))) != 136:\n",
    "#             #error_cases.append(folder)\n",
    "#             pbar.update(1)\n",
    "#             continue\n",
    "   \n",
    "#         slices = {}\n",
    "#         for file in sorted(os.listdir(os.path.join(os.getcwd(), path, folder))):\n",
    "#             ds = pydicom.dcmread(os.path.join(os.getcwd(), path, folder, file))\n",
    "#             slices[ds.SliceLocation] = ds.pixel_array\n",
    "        \n",
    "#         keys = sorted(slices.keys(), reverse = True)\n",
    "#         pixel_array = list(map(slices.get, keys))\n",
    "        \n",
    "#         each_patient = np.array([])  \n",
    "#         for pa in pixel_array:\n",
    "#             if len(each_patient) == 0:\n",
    "#                 each_patient = np.array([pa.reshape(65536)])\n",
    "#             else:\n",
    "#                 each_patient = np.append(each_patient, [pa.reshape(65536)], axis = 0)\n",
    "                \n",
    "# #             print(each_patient)\n",
    "            \n",
    "#         each_patient_T = each_patient.T.reshape(256, 256, 136)\n",
    "#         if len(data) == 0:\n",
    "#             data = np.array([each_patient_T[:, :, :]])\n",
    "#         else:\n",
    "#             data = np.append(data, [each_patient_T[:, :, :]], axis = 0)\n",
    "        \n",
    "# #         for _ in range(5):\n",
    "# #             data = np.append(data, [each_patient_T[:, :, 34+_:98+_]], axis = 0)\n",
    "        \n",
    "#         pbar.update(1)\n",
    "        \n",
    "#     pbar.close()  \n",
    "#     return data\n",
    "\n",
    "# nStroke_data = create_data(\"normal\", \"normal\")\n",
    "# stroke_data = create_data(\"I63\", \"I63\")\n",
    "\n",
    "nStroke_data = np.load(\"normal.npy\")\n",
    "stroke_data = np.load(\"I63.npy\")\n",
    "\n",
    "# np.save('normal', nStroke_data)\n",
    "# np.save('I63', stroke_data)\n",
    "\n",
    "print(\"nStroke_data.shape:\", nStroke_data.shape)\n",
    "print(\"stroke_data.shape:\", stroke_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pltshow(data):\n",
    "#     for i in range(1):\n",
    "#         plt.imshow(np.squeeze(data[:, :, i]), cmap=\"gray\")\n",
    "#         plt.show()\n",
    "\n",
    "# for _ in range(20, 30):\n",
    "#     pltshow(stroke_data_r[_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 128, 128, 128)\n",
      "(70, 128, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "def normalize(data):\n",
    "    _min, _max = 0, 600\n",
    "    data[data < _min] = _min\n",
    "    data[data > _max] = _max\n",
    "    data = (data - _min) / (_max - _min)\n",
    "    data = data.astype(\"float32\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def resize(data):\n",
    "    desired_depth = 128\n",
    "    desired_width = 128\n",
    "    desired_height = 128\n",
    "    current_depth = data.shape[-1]\n",
    "    current_width = data.shape[0]\n",
    "    current_height = data.shape[1]\n",
    "    depth_factor = desired_depth / current_depth\n",
    "    width_factor = desired_width / current_width\n",
    "    height_factor = desired_height / current_height\n",
    "    data = ndimage.zoom(data, (width_factor, height_factor, depth_factor), order=1)\n",
    "    return data\n",
    "\n",
    "def preprocessing(data):\n",
    "    return resize(normalize(data))\n",
    "\n",
    "stroke_data_copy = stroke_data.copy()\n",
    "nStroke_data_copy = nStroke_data.copy()\n",
    "\n",
    "\n",
    "\n",
    "stroke_data1 = np.array([preprocessing(stroke_data_copy[_,:,:,0:128]) for _ in range(stroke_data_copy.shape[0])])\n",
    "nStroke_data1 = np.array([preprocessing(nStroke_data_copy[_,:,:,0:128]) for _ in range(nStroke_data_copy.shape[0])])[0:70]\n",
    "print(stroke_data1.shape)\n",
    "print(nStroke_data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(\"error_cases.txt\", \"w\")\n",
    "# for i in error_cases:\n",
    "#     f.write(i + \"\\n\")\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stroke_labels.shape[0]: 70\n",
      "nStroke_labels.shape[0]: 70\n"
     ]
    }
   ],
   "source": [
    "# 0 : stroke, 1 : not stroke\n",
    "stroke_labels = np.array([0 for _ in range(len(stroke_data1))]) \n",
    "nStroke_labels = np.array([1 for _ in range(len(nStroke_data1))])\n",
    "\n",
    "print(\"stroke_labels.shape[0]:\", stroke_labels.shape[0])\n",
    "print(\"nStroke_labels.shape[0]:\", nStroke_labels.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98, 128, 128, 128) (28, 128, 128, 128) (14, 128, 128, 128)\n",
      "(98,) (28,) (14,)\n",
      "\n",
      "\n",
      "[1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 1 1 0 0\n",
      " 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 0 1 1 0 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 1 0 1 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 0 0 0 1 0 0 0]\n",
      "\n",
      "[1 1 1 0 0 0 1 1 0 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((stroke_data1[:],nStroke_data1[:]), axis=0)\n",
    "Y = np.concatenate((stroke_labels[:],nStroke_labels[:]), axis=0)\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.3)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size=0.33)\n",
    "\n",
    "\n",
    "\n",
    "print(x_train.shape, x_val.shape, x_test.shape)\n",
    "print(y_train.shape, y_val.shape, y_test.shape)\n",
    "print(\"\", y_train, y_val, y_test, sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def rotate(volume):\n",
    "    \n",
    "    def scipy_rotate(volume):\n",
    "        angles = [-10, -5, 0, 5, 10]\n",
    "        angle = random.choice(angles)\n",
    "        volume = ndimage.rotate(volume, angle, reshape=False)\n",
    "        volume[volume < 0] = 0\n",
    "        volume[volume > 1] = 1\n",
    "        return volume\n",
    "\n",
    "    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float32)\n",
    "    return augmented_volume\n",
    "\n",
    "\n",
    "def train_preprocessing(volume, label):\n",
    "    volume = rotate(volume)\n",
    "    volume = tf.expand_dims(volume, axis=-1)\n",
    "    return volume, label\n",
    "\n",
    "\n",
    "def validation_preprocessing(volume, label):\n",
    "    volume = tf.expand_dims(volume, axis=-1)\n",
    "    return volume, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = (\n",
    "    train_loader.shuffle(len(x_train))\n",
    "    .map(train_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(2)\n",
    ")\n",
    "\n",
    "validation_loader = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "validation_dataset = (\n",
    "    validation_loader.shuffle(len(x_val))\n",
    "    .map(validation_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"3dcnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128, 128, 128, 1) 0         \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (None, 126, 126, 126, 32) 896       \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 63, 63, 63, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 63, 63, 63, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 61, 61, 61, 64)    55360     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 30, 30, 30, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 30, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 28, 28, 28, 64)    110656    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 14, 14, 14, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 14, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 12, 12, 12, 128)   221312    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 6, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 6, 6, 6, 128)      512       \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 4, 4, 4, 256)      884992    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 2, 2, 2, 256)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 2, 2, 2, 256)      1024      \n",
      "_________________________________________________________________\n",
      "global_average_pooling3d (Gl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 1,407,489\n",
      "Trainable params: 1,406,401\n",
      "Non-trainable params: 1,088\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model(width=128, height=128, depth=128):\n",
    "\n",
    "    inputs = keras.Input((width, height, depth, 1))\n",
    "\n",
    "    x = layers.Conv3D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    x = layers.Dense(units=512, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    # Define the model.\n",
    "    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Build model.\n",
    "model = get_model(width=128, height=128, depth=128)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100000\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0568s vs `on_train_batch_end` time: 0.0893s). Check your callbacks.\n",
      "49/49 - 22s - loss: 0.7263 - acc: 0.4796 - val_loss: 0.9581 - val_acc: 0.5000\n",
      "Epoch 2/100000\n",
      "49/49 - 22s - loss: 0.6377 - acc: 0.6327 - val_loss: 1.3477 - val_acc: 0.5000\n",
      "Epoch 3/100000\n",
      "49/49 - 22s - loss: 0.6367 - acc: 0.6633 - val_loss: 1.9627 - val_acc: 0.5000\n",
      "Epoch 4/100000\n",
      "49/49 - 22s - loss: 0.6437 - acc: 0.6020 - val_loss: 2.0998 - val_acc: 0.5000\n",
      "Epoch 5/100000\n",
      "49/49 - 22s - loss: 0.6346 - acc: 0.7041 - val_loss: 2.4502 - val_acc: 0.5000\n",
      "Epoch 6/100000\n",
      "49/49 - 22s - loss: 0.6550 - acc: 0.6020 - val_loss: 2.0643 - val_acc: 0.5000\n",
      "Epoch 7/100000\n",
      "49/49 - 22s - loss: 0.5763 - acc: 0.7143 - val_loss: 3.2050 - val_acc: 0.5000\n",
      "Epoch 8/100000\n",
      "49/49 - 22s - loss: 0.6463 - acc: 0.7041 - val_loss: 1.4876 - val_acc: 0.5000\n",
      "Epoch 9/100000\n",
      "49/49 - 22s - loss: 0.6264 - acc: 0.6224 - val_loss: 2.6354 - val_acc: 0.5000\n",
      "Epoch 10/100000\n",
      "49/49 - 22s - loss: 0.5794 - acc: 0.6939 - val_loss: 2.6903 - val_acc: 0.5000\n",
      "Epoch 11/100000\n",
      "49/49 - 22s - loss: 0.5400 - acc: 0.7449 - val_loss: 2.2559 - val_acc: 0.5000\n",
      "Epoch 12/100000\n",
      "49/49 - 23s - loss: 0.5329 - acc: 0.7653 - val_loss: 2.3782 - val_acc: 0.5000\n",
      "Epoch 13/100000\n",
      "49/49 - 22s - loss: 0.5779 - acc: 0.6837 - val_loss: 1.5495 - val_acc: 0.5000\n",
      "Epoch 14/100000\n",
      "49/49 - 22s - loss: 0.5112 - acc: 0.7755 - val_loss: 1.3948 - val_acc: 0.5000\n",
      "Epoch 15/100000\n",
      "49/49 - 22s - loss: 0.4524 - acc: 0.7959 - val_loss: 1.1775 - val_acc: 0.5357\n",
      "Epoch 16/100000\n",
      "49/49 - 22s - loss: 0.4939 - acc: 0.7143 - val_loss: 1.0888 - val_acc: 0.6429\n",
      "Epoch 17/100000\n",
      "49/49 - 22s - loss: 0.4666 - acc: 0.7551 - val_loss: 1.2500 - val_acc: 0.5357\n",
      "Epoch 18/100000\n",
      "49/49 - 22s - loss: 0.4688 - acc: 0.7755 - val_loss: 0.9344 - val_acc: 0.6429\n",
      "Epoch 19/100000\n",
      "49/49 - 22s - loss: 0.4419 - acc: 0.8163 - val_loss: 1.0251 - val_acc: 0.5714\n",
      "Epoch 20/100000\n",
      "49/49 - 22s - loss: 0.3823 - acc: 0.8367 - val_loss: 1.0623 - val_acc: 0.5714\n",
      "Epoch 21/100000\n",
      "49/49 - 22s - loss: 0.4792 - acc: 0.7653 - val_loss: 1.2680 - val_acc: 0.6071\n",
      "Epoch 22/100000\n",
      "49/49 - 22s - loss: 0.3670 - acc: 0.8265 - val_loss: 1.2541 - val_acc: 0.5357\n",
      "Epoch 23/100000\n",
      "49/49 - 22s - loss: 0.3626 - acc: 0.8469 - val_loss: 0.9493 - val_acc: 0.5714\n",
      "Epoch 24/100000\n",
      "49/49 - 22s - loss: 0.3336 - acc: 0.8469 - val_loss: 1.0871 - val_acc: 0.5714\n",
      "Epoch 25/100000\n",
      "49/49 - 22s - loss: 0.4130 - acc: 0.7653 - val_loss: 1.0024 - val_acc: 0.5714\n",
      "Epoch 26/100000\n",
      "49/49 - 22s - loss: 0.3149 - acc: 0.8673 - val_loss: 1.1310 - val_acc: 0.6786\n",
      "Epoch 27/100000\n",
      "49/49 - 22s - loss: 0.3544 - acc: 0.8571 - val_loss: 1.5195 - val_acc: 0.5000\n",
      "Epoch 28/100000\n",
      "49/49 - 22s - loss: 0.3335 - acc: 0.8776 - val_loss: 1.7272 - val_acc: 0.5714\n",
      "Epoch 29/100000\n",
      "49/49 - 22s - loss: 0.3129 - acc: 0.8571 - val_loss: 1.4145 - val_acc: 0.5357\n",
      "Epoch 30/100000\n",
      "49/49 - 22s - loss: 0.2956 - acc: 0.8980 - val_loss: 1.1517 - val_acc: 0.6786\n",
      "Epoch 31/100000\n",
      "49/49 - 22s - loss: 0.2353 - acc: 0.9184 - val_loss: 1.4404 - val_acc: 0.6071\n",
      "Epoch 32/100000\n",
      "49/49 - 22s - loss: 0.2334 - acc: 0.8776 - val_loss: 1.2713 - val_acc: 0.5714\n",
      "Epoch 33/100000\n",
      "49/49 - 22s - loss: 0.2509 - acc: 0.8980 - val_loss: 1.1700 - val_acc: 0.5714\n",
      "Epoch 34/100000\n",
      "49/49 - 22s - loss: 0.2787 - acc: 0.8878 - val_loss: 1.1769 - val_acc: 0.5714\n",
      "Epoch 35/100000\n",
      "49/49 - 22s - loss: 0.2069 - acc: 0.8980 - val_loss: 1.4066 - val_acc: 0.6429\n",
      "Epoch 36/100000\n",
      "49/49 - 22s - loss: 0.2721 - acc: 0.8673 - val_loss: 1.3091 - val_acc: 0.5357\n",
      "Epoch 37/100000\n",
      "49/49 - 23s - loss: 0.1811 - acc: 0.9286 - val_loss: 1.3334 - val_acc: 0.6786\n",
      "Epoch 38/100000\n",
      "49/49 - 22s - loss: 0.1796 - acc: 0.9388 - val_loss: 1.3338 - val_acc: 0.6786\n",
      "Epoch 39/100000\n",
      "49/49 - 22s - loss: 0.2938 - acc: 0.8980 - val_loss: 1.0584 - val_acc: 0.6429\n",
      "Epoch 40/100000\n",
      "49/49 - 22s - loss: 0.1640 - acc: 0.9694 - val_loss: 1.1505 - val_acc: 0.5357\n",
      "Epoch 41/100000\n",
      "49/49 - 22s - loss: 0.1692 - acc: 0.9388 - val_loss: 1.5479 - val_acc: 0.6429\n",
      "Epoch 42/100000\n",
      "49/49 - 22s - loss: 0.1790 - acc: 0.9592 - val_loss: 1.4904 - val_acc: 0.7143\n",
      "Epoch 43/100000\n",
      "49/49 - 22s - loss: 0.1734 - acc: 0.9388 - val_loss: 1.3757 - val_acc: 0.5714\n",
      "Epoch 44/100000\n",
      "49/49 - 22s - loss: 0.2269 - acc: 0.8776 - val_loss: 1.3351 - val_acc: 0.7143\n",
      "Epoch 45/100000\n",
      "49/49 - 22s - loss: 0.1561 - acc: 0.9592 - val_loss: 1.2972 - val_acc: 0.6071\n",
      "Epoch 46/100000\n",
      "49/49 - 22s - loss: 0.2561 - acc: 0.9286 - val_loss: 1.2754 - val_acc: 0.7143\n",
      "Epoch 47/100000\n",
      "49/49 - 22s - loss: 0.1776 - acc: 0.9490 - val_loss: 1.4680 - val_acc: 0.6786\n",
      "Epoch 48/100000\n",
      "49/49 - 22s - loss: 0.1331 - acc: 0.9388 - val_loss: 1.2896 - val_acc: 0.6786\n",
      "Epoch 49/100000\n",
      "49/49 - 22s - loss: 0.1065 - acc: 0.9694 - val_loss: 1.4674 - val_acc: 0.6786\n",
      "Epoch 50/100000\n",
      "49/49 - 22s - loss: 0.1554 - acc: 0.9082 - val_loss: 1.2379 - val_acc: 0.6429\n",
      "Epoch 51/100000\n",
      "49/49 - 22s - loss: 0.1394 - acc: 0.9694 - val_loss: 1.5871 - val_acc: 0.6786\n",
      "Epoch 52/100000\n",
      "49/49 - 22s - loss: 0.1904 - acc: 0.9184 - val_loss: 1.2704 - val_acc: 0.7143\n",
      "Epoch 53/100000\n",
      "49/49 - 22s - loss: 0.1914 - acc: 0.9286 - val_loss: 1.4960 - val_acc: 0.6429\n",
      "Epoch 54/100000\n",
      "49/49 - 22s - loss: 0.0932 - acc: 0.9898 - val_loss: 1.5423 - val_acc: 0.6071\n",
      "Epoch 55/100000\n",
      "49/49 - 22s - loss: 0.0836 - acc: 0.9898 - val_loss: 1.4644 - val_acc: 0.6429\n",
      "Epoch 56/100000\n",
      "49/49 - 22s - loss: 0.1086 - acc: 0.9490 - val_loss: 1.8158 - val_acc: 0.6429\n",
      "Epoch 57/100000\n",
      "49/49 - 22s - loss: 0.0802 - acc: 0.9694 - val_loss: 1.9789 - val_acc: 0.6071\n",
      "Epoch 58/100000\n",
      "49/49 - 22s - loss: 0.1642 - acc: 0.9388 - val_loss: 1.5061 - val_acc: 0.5714\n",
      "Epoch 59/100000\n",
      "49/49 - 22s - loss: 0.0975 - acc: 0.9694 - val_loss: 1.8497 - val_acc: 0.6786\n",
      "Epoch 60/100000\n",
      "49/49 - 22s - loss: 0.1372 - acc: 0.9490 - val_loss: 1.4175 - val_acc: 0.6786\n",
      "Epoch 61/100000\n",
      "49/49 - 22s - loss: 0.0878 - acc: 1.0000 - val_loss: 1.3956 - val_acc: 0.6429\n",
      "Epoch 62/100000\n",
      "49/49 - 22s - loss: 0.1411 - acc: 0.9082 - val_loss: 1.6769 - val_acc: 0.7143\n",
      "Epoch 63/100000\n",
      "49/49 - 22s - loss: 0.1429 - acc: 0.9286 - val_loss: 1.4124 - val_acc: 0.6429\n",
      "Epoch 64/100000\n",
      "49/49 - 22s - loss: 0.1267 - acc: 0.9490 - val_loss: 1.6445 - val_acc: 0.6071\n",
      "Epoch 65/100000\n",
      "49/49 - 22s - loss: 0.0785 - acc: 0.9796 - val_loss: 1.4155 - val_acc: 0.5357\n",
      "Epoch 66/100000\n",
      "49/49 - 22s - loss: 0.1220 - acc: 0.9592 - val_loss: 1.8758 - val_acc: 0.5357\n",
      "Epoch 67/100000\n",
      "49/49 - 22s - loss: 0.1298 - acc: 0.9592 - val_loss: 2.1905 - val_acc: 0.5714\n",
      "Epoch 68/100000\n",
      "49/49 - 22s - loss: 0.1303 - acc: 0.9490 - val_loss: 1.6552 - val_acc: 0.7143\n",
      "Epoch 69/100000\n",
      "49/49 - 22s - loss: 0.1195 - acc: 0.9388 - val_loss: 1.4545 - val_acc: 0.6786\n",
      "Epoch 70/100000\n",
      "49/49 - 22s - loss: 0.1125 - acc: 0.9796 - val_loss: 1.6108 - val_acc: 0.6071\n",
      "Epoch 71/100000\n",
      "49/49 - 22s - loss: 0.1026 - acc: 0.9592 - val_loss: 1.7971 - val_acc: 0.6429\n",
      "Epoch 72/100000\n",
      "49/49 - 22s - loss: 0.0968 - acc: 0.9592 - val_loss: 1.5813 - val_acc: 0.6429\n",
      "Epoch 73/100000\n",
      "49/49 - 22s - loss: 0.1261 - acc: 0.9592 - val_loss: 1.7102 - val_acc: 0.5714\n",
      "Epoch 74/100000\n",
      "49/49 - 23s - loss: 0.0642 - acc: 0.9796 - val_loss: 1.5605 - val_acc: 0.6786\n",
      "Epoch 75/100000\n",
      "49/49 - 22s - loss: 0.0617 - acc: 0.9898 - val_loss: 1.5946 - val_acc: 0.5714\n",
      "Epoch 76/100000\n",
      "49/49 - 22s - loss: 0.0350 - acc: 1.0000 - val_loss: 1.7116 - val_acc: 0.6786\n",
      "Epoch 77/100000\n",
      "49/49 - 22s - loss: 0.0988 - acc: 0.9694 - val_loss: 1.6117 - val_acc: 0.6786\n",
      "Epoch 78/100000\n",
      "49/49 - 22s - loss: 0.1026 - acc: 0.9592 - val_loss: 1.8923 - val_acc: 0.6071\n",
      "Epoch 79/100000\n",
      "49/49 - 22s - loss: 0.0738 - acc: 0.9796 - val_loss: 2.0620 - val_acc: 0.5714\n",
      "Epoch 80/100000\n",
      "49/49 - 22s - loss: 0.0633 - acc: 0.9592 - val_loss: 2.0406 - val_acc: 0.6786\n",
      "Epoch 81/100000\n",
      "49/49 - 22s - loss: 0.0429 - acc: 1.0000 - val_loss: 1.9937 - val_acc: 0.6071\n",
      "Epoch 82/100000\n",
      "49/49 - 22s - loss: 0.0677 - acc: 0.9592 - val_loss: 2.2143 - val_acc: 0.5357\n",
      "Epoch 83/100000\n",
      "49/49 - 22s - loss: 0.0740 - acc: 0.9796 - val_loss: 2.4011 - val_acc: 0.7143\n",
      "Epoch 84/100000\n",
      "49/49 - 22s - loss: 0.0742 - acc: 0.9592 - val_loss: 2.0723 - val_acc: 0.5714\n",
      "Epoch 85/100000\n",
      "49/49 - 22s - loss: 0.1082 - acc: 0.9694 - val_loss: 2.1185 - val_acc: 0.6429\n",
      "Epoch 86/100000\n",
      "49/49 - 22s - loss: 0.1063 - acc: 0.9490 - val_loss: 1.9325 - val_acc: 0.6429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100000\n",
      "49/49 - 22s - loss: 0.0783 - acc: 0.9796 - val_loss: 1.8741 - val_acc: 0.7143\n",
      "Epoch 88/100000\n",
      "49/49 - 22s - loss: 0.0824 - acc: 0.9694 - val_loss: 2.0783 - val_acc: 0.6071\n",
      "Epoch 89/100000\n",
      "49/49 - 22s - loss: 0.0869 - acc: 0.9796 - val_loss: 2.0064 - val_acc: 0.5357\n",
      "Epoch 90/100000\n",
      "49/49 - 22s - loss: 0.0394 - acc: 0.9898 - val_loss: 1.8356 - val_acc: 0.6071\n",
      "Epoch 91/100000\n",
      "49/49 - 22s - loss: 0.0817 - acc: 0.9796 - val_loss: 1.7526 - val_acc: 0.6429\n",
      "Epoch 92/100000\n",
      "49/49 - 22s - loss: 0.0692 - acc: 0.9694 - val_loss: 1.3648 - val_acc: 0.6429\n",
      "Epoch 93/100000\n",
      "49/49 - 22s - loss: 0.0749 - acc: 0.9694 - val_loss: 1.5766 - val_acc: 0.6786\n",
      "Epoch 94/100000\n",
      "49/49 - 22s - loss: 0.0592 - acc: 0.9796 - val_loss: 2.2755 - val_acc: 0.5357\n",
      "Epoch 95/100000\n",
      "49/49 - 22s - loss: 0.0678 - acc: 0.9796 - val_loss: 1.6371 - val_acc: 0.6429\n",
      "Epoch 96/100000\n",
      "49/49 - 22s - loss: 0.0607 - acc: 0.9796 - val_loss: 1.7416 - val_acc: 0.6786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29f580b1630>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.0001,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"acc\"],\n",
    ")\n",
    "\n",
    "# Reduce = ReduceLROnPlateau(monitor='val_loss',\n",
    "#                            factor=0.1,\n",
    "#                            patience=1,\n",
    "#                            min_lr=0)\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"loss\", patience=20, mode=\"min\", restore_best_weights=True)\n",
    "\n",
    "# Train the model, doing validation at the end of each epoch\n",
    "epochs = 100000\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    callbacks=[early_stopping],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(os.path.join(\n",
    "#     os.getcwd(), \"H5\", \"TEST_\" + str(date.today()) + \" \" + str(datetime.now().strftime(\"%H:%M:%S\")).replace(\":\", \"_\") + \".h5\"\n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_load' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d327c77b5bc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcases\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_load\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpredict_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_load' is not defined"
     ]
    }
   ],
   "source": [
    "cases = 14\n",
    "NN = 0\n",
    "NA = 0\n",
    "AN = 0\n",
    "AA = 0\n",
    "\n",
    "\n",
    "class_names = [\"stroke    \", \"not stroke\"]\n",
    "\n",
    "for _ in range(cases):\n",
    "    prediction = model_load.predict(np.expand_dims(x_test[_], axis=0))[0]\n",
    "    scores = [1 - prediction[0], prediction[0]]\n",
    "    if scores[0] < scores[1]: predict_code = 1 \n",
    "    else: predict_code = 0\n",
    "    if y_test[_] == 1 and predict_code == 1:\n",
    "        print(\"Correct  \", \"Actual:\", class_names[y_test[_]], \"Predict:\", class_names[predict_code], sep=\"  \")\n",
    "        NN += 1\n",
    "    if y_test[_] == 1 and predict_code == 0:\n",
    "        print(\"Incorrect\", \"Actual:\", class_names[y_test[_]], \"Predict:\", class_names[predict_code], sep=\"  \")\n",
    "        NA += 1\n",
    "    if y_test[_] == 0 and predict_code == 1:\n",
    "        print(\"Incorrect\", \"Actual:\", class_names[y_test[_]], \"Predict:\", class_names[predict_code], sep=\"  \")\n",
    "        AN += 1\n",
    "    if y_test[_] == 0 and predict_code == 0:\n",
    "        print(\"Correct  \", \"Actual:\", class_names[y_test[_]], \"Predict:\", class_names[predict_code], sep=\"  \")\n",
    "        AA += 1\n",
    "\n",
    "confusion_mat = pd.DataFrame(\n",
    "    [[NN, NA], [AN, AA]], \\\n",
    "    index=pd.MultiIndex.from_product([[\"Actual\"],[\"Normal\", \"Abnormal\"]]), \\\n",
    "    columns=pd.MultiIndex.from_product([[\"Predict\"],[\"Normal\", \"Abnormal\"]])\n",
    ")\n",
    "\n",
    "confusion_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}